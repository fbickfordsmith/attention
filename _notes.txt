----------
NEXT STEPS

- split up activations
- time a forward pass with precomputed conv5 output

----------
CODE REMINDERS

- get updated semcontext definitions
- revert attention_position
- revert losses and metrics
- revert _v6.npy
- revert data_aug

----------
NOTES TO WRITE UP

using diagonal covariance,
- mahalanobis_v3.py takes 20s/loop * 1000loops = 5.5hr
- kl_divergence_v2.py takes 40s/loop * 1000loops = 11hr
- similarity_dotproduct_np2.py with num_samples=125 takes 17s/loop * 1000loops = 4.5hr
distances are (much) slower to compute with full covariance

perceptual similarity on val_white
- vgg takes 30s/loop * 500,500loops = 4170hr
- alexnet takes 20s/loop
- squeezenet takes 30s/loop

----------
EXPERIMENT PLAN

difficulty
- redefine
- run x 1

size
- redefine?
- run x 3

semantic
- redefine
- run x 1

similarity
- redefine?
- run x 1?

{diff, size, sim}-controlled semantic
- define x 3
- run x 3

write thesis without looking at references -- just type!
overall difficulty -> average difficulty
